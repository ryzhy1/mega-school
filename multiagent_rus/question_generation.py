import json
import logging
from typing import Tuple

from config import DEBUG_RAG, llm
from helpers import extract_json_object, safe_print
from models import QAItem
from rag_store import rag_context_for


def is_context_good(ctx: str) -> bool:
    if not ctx:
        return False
    return ("[Source:" in ctx) and (len(ctx) >= 220)


def is_grounded_answer(expected: str, key_points: list, ctx: str) -> bool:
    if not expected or not ctx:
        return False
    if expected not in ctx:
        return False
    for kp in (key_points or []):
        if kp and kp not in ctx:
            return False
    return True


def debug_block(title: str, payload: str, limit: int = 900):
    if not DEBUG_RAG:
        return
    safe_print("\n" + "‚ïê" * 80)
    safe_print(f"üîé DEBUG: {title}")
    safe_print("‚îÄ" * 80)
    if payload is None:
        safe_print("(None)")
    else:
        payload = str(payload)
        if len(payload) > limit:
            safe_print(payload[:limit] + f"\n...[trimmed {len(payload)-limit} chars]")
        else:
            safe_print(payload)
    safe_print("‚ïê" * 80 + "\n")


def generate_question_from_context(tech: str, difficulty: int, rag_ctx: str) -> QAItem:
    prompt = f"""
–¢—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –û–î–ò–ù –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {tech}.
–°–ª–æ–∂–Ω–æ—Å—Ç—å: {difficulty}/5.

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1) –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏–∑ CONTEXT –Ω–∏–∂–µ.
2) expected_answer –î–û–õ–ñ–ï–ù –±—ã—Ç—å –¢–û–ß–ù–û–ô –ø–æ–¥—Å—Ç—Ä–æ–∫–æ–π (exact substring) –∏–∑ CONTEXT (–≤–∫–ª—é—á–∞—è token., go/parser –∏ —Ç.–¥.).
3) key_points: –∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç —Ç–æ–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–¥—Å—Ç—Ä–æ–∫–æ–π –∏–∑ CONTEXT.
4) –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è ‚Äî –≤–µ—Ä–Ω–∏ expected_answer –ø—É—Å—Ç—ã–º –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å –ø–æ CONTEXT.

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
{{
  "question": "...",
  "expected_answer": "...",
  "key_points": ["...", "..."],
  "topic": "..."
}}


CONTEXT:
{rag_ctx}
"""
    resp = llm.invoke([("human", prompt)])
    obj = extract_json_object(resp.content)
    try:
        data = json.loads(obj)
    except Exception:
        data = {
            "question": f"–†–∞—Å—Å–∫–∞–∂–∏ –±–∞–∑–æ–≤–æ –ø—Ä–æ {tech}.",
            "expected_answer": "",
            "key_points": [],
            "topic": tech,
        }
    try:
        return QAItem(**data)
    except Exception:
        return QAItem(question=f"–†–∞—Å—Å–∫–∞–∂–∏ –±–∞–∑–æ–≤–æ –ø—Ä–æ {tech}.", topic=tech)


def build_expected_for_question(tech: str, question: str, rag_ctx: str) -> QAItem:
    """
    –î–ª—è —É–∂–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –¥–æ—Å—Ç–∞—ë–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (expected_answer)
    –∏ key_points —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ –±—ã–ª–∏ exact substring –∏–∑ rag_ctx.
    """
    prompt = f"""
–¢—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã–ø–∏—Å–∞—Ç—å —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ CONTEXT –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ QUESTION.

–ñ–Å–°–¢–ö–ò–ï –ü–†–ê–í–ò–õ–ê:
1) expected_answer –î–û–õ–ñ–ï–ù –±—ã—Ç—å –¢–û–ß–ù–û–ô –ø–æ–¥—Å—Ç—Ä–æ–∫–æ–π (exact substring) –∏–∑ CONTEXT (—Å —Ç–µ–º–∏ –∂–µ —Å–∏–º–≤–æ–ª–∞–º–∏).
2) key_points: –∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç —Ç–æ–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–ß–ù–û–ô –ø–æ–¥—Å—Ç—Ä–æ–∫–æ–π –∏–∑ CONTEXT.
3) –ï—Å–ª–∏ –≤ CONTEXT –Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ ‚Äî –≤–µ—Ä–Ω–∏ expected_answer –ø—É—Å—Ç—ã–º –∏ key_points [].
4) –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON.

TECH: {tech}
QUESTION: {question}

CONTEXT:
{rag_ctx}

–í–µ—Ä–Ω–∏ JSON:
{{
  "question": "{question}",
  "expected_answer": "...",
  "key_points": ["...", "..."],
  "topic": "..."
}}
"""
    resp = llm.invoke([("human", prompt)])
    obj = extract_json_object(resp.content)

    try:
        data = json.loads(obj)
    except Exception:
        return QAItem(question=question, expected_answer="", key_points=[], topic=tech)

    try:
        qa = QAItem(**data)
    except Exception:
        qa = QAItem(question=question, expected_answer="", key_points=[], topic=tech)

    if not is_grounded_answer(qa.expected_answer, qa.key_points, rag_ctx):
        return QAItem(question=question, expected_answer="", key_points=[], topic=qa.topic or tech)

    qa.question = question
    return qa


def ensure_expected_from_rag(tech: str, question: str, topic_seed: str) -> Tuple[QAItem, str]:
    """
    1) –†–µ—Ç—Ä–∏–≤–∏–º rag_ctx –ø–æ topic_seed/–≤–æ–ø—Ä–æ—Å—É
    2) –ü—ã—Ç–∞–µ–º—Å—è –ø–æ—Å—Ç—Ä–æ–∏—Ç—å expected_answer/key_points –∫–∞–∫ exact substring
    3) –ï—Å–ª–∏ –Ω–µ –≤—ã—à–ª–æ ‚Äî –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ä–µ—Ç—Ä–∏–≤
    """
    rag_ctx = rag_context_for(topic_seed, tech=tech, k=4)
    if not is_context_good(rag_ctx):
        rag_ctx = rag_context_for(question, tech=tech, k=4)

    if not is_context_good(rag_ctx):
        return QAItem(question=question, expected_answer="", key_points=[], topic=tech), rag_ctx or ""

    qa = build_expected_for_question(tech, question, rag_ctx)
    if qa.expected_answer:
        return qa, rag_ctx

    rag_ctx2 = rag_context_for(f"{tech} {topic_seed} reference", tech=tech, k=4)
    if is_context_good(rag_ctx2):
        qa2 = build_expected_for_question(tech, question, rag_ctx2)
        if qa2.expected_answer:
            return qa2, rag_ctx2

    return qa, rag_ctx


def make_answerable_question(
    tech: str,
    difficulty: int,
    max_tries: int = 3,
    focus_topic: str = "",
) -> Tuple[QAItem, str]:
    """
    Generate a question that is answerable from current RAG context.
    """
    difficulty = max(1, min(5, difficulty))

    seed_queries = [
        f"{tech} introduction overview",
        f"{tech} basic concepts",
        f"{tech} api reference",
        f"{tech} examples tutorial",
        f"{tech} edge cases best practices",
    ]

    seed_query = (f"{tech} {focus_topic}".strip() if focus_topic else seed_queries[difficulty - 1])

    for attempt in range(1, max_tries + 1):
        rag_ctx = rag_context_for(seed_query, tech=tech, k=4)
        if not is_context_good(rag_ctx):
            rag_ctx = rag_context_for(tech, tech=tech, k=4)

        debug_block(
            f"QuestionGen attempt={attempt} tech={tech} difficulty={difficulty} seed_query='{seed_query}' "
            f"(RAG ctx used for generation)",
            rag_ctx,
        )

        if not is_context_good(rag_ctx):
            debug_block("QuestionGen: RAG ctx is NOT good (will retry)", f"len={len(rag_ctx)}")
            seed_query = f"{seed_query} reference"
            continue

        qa = generate_question_from_context(tech, difficulty, rag_ctx)

        if not is_grounded_answer(qa.expected_answer, qa.key_points, rag_ctx):
            debug_block(
                "‚ùå NOT GROUNDED: expected_answer/key_points not in generation ctx",
                f"expected={qa.expected_answer}\nkey_points={qa.key_points}",
            )
            if qa.topic:
                seed_query = f"{tech} {qa.topic} reference"
            else:
                seed_query = f"{seed_query} reference"
            continue

        check_ctx = rag_context_for(qa.question, tech=tech, k=2)
        debug_block("Validation RAG ctx (retrieved by the question)", check_ctx)
        debug_block("Is answerable by RAG?", str(is_context_good(check_ctx)))

        if is_context_good(check_ctx):
            return qa, check_ctx

        if qa.topic:
            seed_query = f"{tech} {qa.topic} reference"
        else:
            seed_query = f"{seed_query} reference"

    debug_block("QuestionGen fallback", f"tech={tech} difficulty={difficulty} -> generic question (no RAG)")
    return (
        QAItem(
            question=f"–†–∞—Å—Å–∫–∞–∂–∏, —á—Ç–æ —Ç–∞–∫–æ–µ {tech}, –≥–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏ –∫–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è —Ç—ã –∑–Ω–∞–µ—à—å?",
            expected_answer="",
            key_points=[],
            topic=tech,
        ),
        "",
    )
