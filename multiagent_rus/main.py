import asyncio
import json
import logging
import re
from typing import Any, Dict

from devdocs_loader import (
    background_load_other_techs,
    load_devdocs_for_tech,
    load_devdocs_for_tech_with_topics,
)
from feedback import generate_final_feedback
from helpers import ainput, safe_print
from interview_plan import (
    generate_interview_plan,
    generate_role_question,
    normalize_topic_seed,
    pop_next_question_for_tech,
)
from interviewer import build_interviewer_visible_message
from logger import InterviewLogger
from mcp_client import MCPServerClient
from models import QAItem
from observer import observer_analyze
from question_generation import ensure_expected_from_rag, make_answerable_question
from tech_extraction import extract_tech_slugs_from_user_text


async def run_interview():
    safe_print("=== MULTI-AGENT INTERVIEW COACH (Primary-first + Parallel RAG) ===\n")

    logger = InterviewLogger(team_name="–°–∫–∏—Ä–ª—è–∫ –Ø—Ä–æ—Å–ª–∞–≤ –Æ—Ä—å–µ–≤–∏—á", filename="logs/interview_log.json")
    mcp = MCPServerClient(server_script="server.py")

    try:
        name = (await ainput("üë§ –ò–º—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (Alex): ")).strip() or "Alex"
        position = (await ainput("üíº –ü–æ–∑–∏—Ü–∏—è (Backend Developer): ")).strip() or "Backend Developer"
        grade = (await ainput("üìä –£—Ä–æ–≤–µ–Ω—å (Junior): ")).strip() or "Junior"

        profile: Dict[str, Any] = {"name": name, "position": position, "grade": grade}

        stack_text = (await ainput("\nüîß –û–ø–∏—à–∏ —Å–≤–æ–π —Å—Ç–µ–∫ (–º–æ–∂–Ω–æ –ø–æ-—Ä—É—Å—Å–∫–∏): ")).strip()

        techs = extract_tech_slugs_from_user_text(stack_text)
        domain_mode = False
        if not techs:
            domain_mode = True
            safe_print("‚ÑπÔ∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã ‚Äî –ø–µ—Ä–µ–π–¥—É –∫ –≤–æ–ø—Ä–æ—Å–∞–º –ø–æ —Ä–æ–ª–∏ –∏ –æ–ø—ã—Ç—É –≤ IT.")

        primary = techs[0] if techs else ""
        pending = techs[1:] if techs else []
        current_tech = primary

        profile["technologies"] = techs
        if techs:
            safe_print(f"\nüéØ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {techs}")
            safe_print(f"‚≠ê Primary tech: {primary}")
            if pending:
                safe_print(f"‚è≥ Pending (background): {pending}")

        topics_map = {}
        questions_queue = []
        if not domain_mode:
            safe_print("\nüß≠ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –ø–ª–∞–Ω –∏–Ω—Ç–µ—Ä–≤—å—é (—Ç–µ–º—ã –∏ –Ω–∞—á–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã)...")
            plan = generate_interview_plan(mcp, grade, position, techs, per_tech=3)
            topics_map = plan.get("topics_map", {})
            questions_queue = plan.get("questions_queue", [])
            safe_print(f"üîé –ü–ª–∞–Ω –ø–æ —Ç–µ–º–∞–º: {topics_map}")
            safe_print(f"üóÇÔ∏è –í–æ–ø—Ä–æ—Å–æ–≤ –≤ –æ—á–µ—Ä–µ–¥–∏: {len(questions_queue)}")

        loaded_techs = set()
        if not domain_mode:
            safe_print(f"\n‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –ø–µ—Ä–≤–∏—á–Ω–æ–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {primary}")
            primary_topics = topics_map.get(primary, [])
            if primary_topics:
                ok_primary = await asyncio.to_thread(
                    load_devdocs_for_tech_with_topics,
                    mcp,
                    primary,
                    primary_topics,
                    3,
                )
            else:
                ok_primary = await asyncio.to_thread(load_devdocs_for_tech, mcp, primary, 3)

            if ok_primary:
                loaded_techs.add(primary)
                safe_print(f"‚úÖ Primary RAG ready: {primary}")
            else:
                safe_print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å DevDocs –ø–æ {primary}. –ü—Ä–æ–¥–æ–ª–∂—É –±–µ–∑ –≥–∞—Ä–∞–Ω—Ç–∏–π RAG.")

        bg_task = None
        if pending and not domain_mode:
            bg_task = asyncio.create_task(
                background_load_other_techs(mcp, pending, loaded_techs, topics_map)
            )

        evaluation: Dict[str, Any] = {
            "topics": [],
            "confirmed": [],
            "gaps": [],
            "turns": [],
            "soft_notes": [],
            "signals": {"hallucination": 0, "off_topic": 0, "candidate_question": 0},
        }

        difficulty = 1
        last_agent_message = ""

        if domain_mode:
            opening_question = await asyncio.to_thread(generate_role_question, grade, position, "", "")
            qa = QAItem(question=opening_question, expected_answer="", key_points=[], topic=position)
            rag_ctx = ""
            last_agent_message = (
                f"–ü—Ä–∏–≤–µ—Ç, {name}! –î–∞–≤–∞–π –Ω–∞—á–Ω–µ–º –∏–Ω—Ç–µ—Ä–≤—å—é –ø–æ —Ä–æ–ª–∏ {position}.\n\n{qa.question}"
            )
        else:
            first = pop_next_question_for_tech(questions_queue, primary)
            if first:
                q_text = first.get("question", f"–†–∞—Å—Å–∫–∞–∂–∏ –±–∞–∑–æ–≤–æ –ø—Ä–æ {primary}.")
                seed = normalize_topic_seed(first.get("topic", ""), primary)

                qa, rag_ctx = await asyncio.to_thread(ensure_expected_from_rag, primary, q_text, seed)

                if not qa.expected_answer:
                    qa, rag_ctx = await asyncio.to_thread(
                        make_answerable_question,
                        primary,
                        difficulty,
                        3,
                        focus_topic=first.get("topic", ""),
                    )
            else:
                qa, rag_ctx = await asyncio.to_thread(make_answerable_question, primary, difficulty, 3)
            last_agent_message = f"–ü—Ä–∏–≤–µ—Ç, {name}! –î–∞–≤–∞–π –Ω–∞—á–Ω–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∏–Ω—Ç–µ—Ä–≤—å—é –ø–æ {primary}.\n\n{qa.question}"
        safe_print(f"\nü§ñ Interviewer:\n{last_agent_message}")

        safe_print("\n(–í–≤–µ–¥–∏ '—Å—Ç–æ–ø' —á—Ç–æ–±—ã –∑–∞–∫–æ–Ω—á–∏—Ç—å –∏ –ø–æ–ª—É—á–∏—Ç—å —Ñ–∏–¥–±—ç–∫)\n")

        while True:
            user_input = (await ainput("üë§ –¢—ã: ")).strip()

            if user_input.lower() in ["—Å—Ç–æ–ø", "stop", "exit", "–≤—ã—Ö–æ–¥"]:
                internal_thoughts = "[Observer]: stop requested. [Interviewer]: generate final feedback."
                logger.log_turn(user_msg=user_input, agent_msg=last_agent_message, thoughts=internal_thoughts)
                break

            if not user_input:
                safe_print("ü§ñ Interviewer: –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ –Ω–∞–ø–∏—à–∏ '—Å—Ç–æ–ø').")
                continue

            try:
                safe_print(f"üë§ {user_input}")
            except Exception:
                logging.info(f"Candidate answer: {user_input}")

            obs = await asyncio.to_thread(
                observer_analyze,
                current_tech or position,
                qa.question,
                user_input,
                qa,
                rag_ctx,
            )

            if obs.flags.get("hallucination_detected"):
                evaluation["signals"]["hallucination"] += 1
            if obs.flags.get("off_topic"):
                evaluation["signals"]["off_topic"] += 1
            if obs.flags.get("candidate_question"):
                evaluation["signals"]["candidate_question"] += 1

            topic = (obs.assessment or {}).get("topic") or qa.topic or primary or position
            if topic and topic not in evaluation["topics"]:
                evaluation["topics"].append(topic)

            correctness = (obs.assessment or {}).get("correctness", "medium")
            missing_points = (obs.assessment or {}).get("missing_points", []) or []
            correct_short = (obs.assessment or {}).get("correct_answer_short", "") or ""

            evaluation["turns"].append(
                {
                    "tech": primary,
                    "topic": topic,
                    "question": qa.question,
                    "user_answer": user_input,
                    "correctness": correctness,
                    "missing_points": missing_points,
                    "correct_answer_short": correct_short,
                }
            )

            if correctness == "high":
                tag = f"{primary}:{topic}"
                if tag not in evaluation["confirmed"]:
                    evaluation["confirmed"].append(tag)
            elif correctness == "low":
                evaluation["gaps"].append(
                    {
                        "topic": f"{primary}:{topic}",
                        "issue": "–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏/–ø—Ä–æ–±–µ–ª—ã.",
                        "correct_answer": correct_short
                        or qa.expected_answer
                        or "–°–º. –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é DevDocs –ø–æ —Ç–µ–º–µ.",
                    }
                )

            if obs.difficulty_adjustment == "increase":
                difficulty = min(5, difficulty + 1)
            elif obs.difficulty_adjustment == "decrease":
                difficulty = max(1, difficulty - 1)

            thoughts = (
                f"[Observer]: {obs.internal_thoughts} [Interviewer]: will_follow='{obs.instruction_to_interviewer}'"
            )
            logger.log_turn(user_msg=user_input, agent_msg=last_agent_message, thoughts=thoughts)

            if obs.topic_status == "wrap_up":
                break

            prev_question = qa.question

            if domain_mode:
                next_question = await asyncio.to_thread(
                    generate_role_question,
                    grade,
                    position,
                    qa.question,
                    user_input,
                )
                qa = QAItem(question=next_question, expected_answer="", key_points=[], topic=position)
                rag_ctx = ""
            else:
                if questions_queue:
                    nxt = pop_next_question_for_tech(questions_queue, current_tech) or questions_queue.pop(0)
                    q_text = nxt.get("question", f"–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ {current_tech} –±–∞–∑–æ–≤–æ.")
                    nxt_topic = nxt.get("topic", current_tech)
                    seed = normalize_topic_seed(nxt_topic, current_tech)

                    qa, rag_ctx = await asyncio.to_thread(ensure_expected_from_rag, current_tech, q_text, seed)

                    if not qa.expected_answer:
                        qa, rag_ctx = await asyncio.to_thread(
                            make_answerable_question,
                            current_tech,
                            difficulty,
                            3,
                            focus_topic=nxt_topic,
                        )
                else:
                    qa, rag_ctx = await asyncio.to_thread(make_answerable_question, current_tech, difficulty, 3)
            history_summary = (
                f"–¢–µ–∫—É—â–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è: {primary or '—Ä–æ–ª—å'}. "
                f"–ü–æ—Å–ª–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {(obs.assessment or {}).get('correctness', '')}."
            )

            reaction = await asyncio.to_thread(
                build_interviewer_visible_message,
                profile,
                current_tech,
                qa.question,
                obs,
                user_input,
                prev_question,
                history_summary,
            )

            reaction = (reaction or "").strip()

            next_tech = ""
            match = re.search(r"__NEXT_TECH__=([a-z0-9_+-]*)", reaction)
            if match:
                next_tech = (match.group(1) or "").strip().lower()

            reaction = re.sub(r"\n?__NEXT_TECH__=.*(\n)?", "\n", reaction).strip()

            if next_tech:
                allowed = (profile.get("technologies") or [])
                if next_tech in allowed:
                    current_tech = next_tech

            last_agent_message = (reaction + "\n\n" if reaction else "")
            safe_print(f"\nü§ñ Interviewer:\n{last_agent_message}\n")

        if bg_task:
            try:
                await asyncio.wait_for(bg_task, timeout=3.0)
            except asyncio.TimeoutError:
                pass
            except Exception:
                pass

        feedback = await asyncio.to_thread(generate_final_feedback, profile, evaluation)
        logger.log_feedback(feedback)

        safe_print("\nüìä FINAL FEEDBACK (saved to interview_log_1.json):\n")
        safe_print(json.dumps(feedback, ensure_ascii=False, indent=2))

        safe_print("\nüèÅ Done. Log file: interview_log_1.json")

    finally:
        try:
            mcp.close()
        except Exception:
            pass


if __name__ == "__main__":
    asyncio.run(run_interview())
